{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Neural Translation English - Germany",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsX0L1sG1iZj"
      },
      "source": [
        "# Capstone Project\n",
        "## Neural translation model\n",
        "### Instructions\n",
        "\n",
        "In this notebook, you will create a neural network that translates from English to German. You will use concepts from throughout this course, including building more flexible model architectures, freezing layers, data processing pipeline and sequence modelling.\n",
        "\n",
        "This project is peer-assessed. Within this notebook you will find instructions in each section for how to complete the project. Pay close attention to the instructions as the peer review will be carried out according to a grading rubric that checks key parts of the project instructions. Feel free to add extra cells into the notebook as required.\n",
        "\n",
        "### How to submit\n",
        "\n",
        "When you have completed the Capstone project notebook, you will submit a pdf of the notebook for peer review. First ensure that the notebook has been fully executed from beginning to end, and all of the cell outputs are visible. This is important, as the grading rubric depends on the reviewer being able to view the outputs of your notebook. Save the notebook as a pdf (you could download the notebook with File -> Download .ipynb, open the notebook locally, and then File -> Download as -> PDF via LaTeX), and then submit this pdf for review.\n",
        "\n",
        "### Let's get started!\n",
        "\n",
        "We'll start by running some imports, and loading the dataset. For this project you are free to make further imports throughout the notebook as you wish. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raywumvvZT2m",
        "outputId": "aa79ae94-01f5-430f-a924-6802f21d0c63"
      },
      "source": [
        "!pip install tensorflow_text --quiet"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.9 MB 4.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VyTvxPN1iZn"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import string\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nw99tEEQ3bKL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f496ec7a-b780-4383-b89f-d2ff2352c937"
      },
      "source": [
        "# Run this cell to connect to your Drive folder\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8PetPpw1iZu"
      },
      "source": [
        "# Run this cell to load the dataset\n",
        "\n",
        "text_pairs = []\n",
        "with open('/content/gdrive/MyDrive/deu.txt', 'r', encoding='utf8') as f:\n",
        "    for line in f.readlines():\n",
        "      eng, gem, src = line.split('\\t')\n",
        "      text_pairs.append((eng, gem))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RrCiABx1T2g",
        "outputId": "83c74b0a-60cb-4cda-d62a-a033b12bde22"
      },
      "source": [
        "text_pairs[:5]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Hi.', 'Hallo!'),\n",
              " ('Hi.', 'Grüß Gott!'),\n",
              " ('Run!', 'Lauf!'),\n",
              " ('Wow!', 'Potzdonner!'),\n",
              " ('Wow!', 'Donnerwetter!')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z70nu6_01iZ3"
      },
      "source": [
        "## 1. Text preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnIdqZFk1iaA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70f4d85c-2365-46de-c03c-9d9122b1759e"
      },
      "source": [
        "random.shuffle(text_pairs)\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples :]\n",
        "\n",
        "print(f\"{len(text_pairs)} total pairs\")\n",
        "print(f\"{len(train_pairs)} training pairs\")\n",
        "print(f\"{len(val_pairs)} validation pairs\")\n",
        "print(f\"{len(test_pairs)} test pairs\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200519 total pairs\n",
            "140365 training pairs\n",
            "30077 validation pairs\n",
            "30077 test pairs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LnyMAVJ5eiM"
      },
      "source": [
        "import string"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dA8xzlCe4tng"
      },
      "source": [
        "vocab_size = 15000\n",
        "sequence_length = 20\n",
        "batch_size = 64\n",
        "\n",
        "\n",
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accecented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text\n",
        "\n",
        "\n",
        "eng_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size, output_mode=\"int\", output_sequence_length=sequence_length,\n",
        ")\n",
        "gem_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=tf_lower_and_split_punct,\n",
        ")\n",
        "train_eng_texts = [pair[0] for pair in train_pairs]\n",
        "train_gem_texts = [pair[1] for pair in train_pairs]\n",
        "eng_vectorization.adapt(train_eng_texts)\n",
        "gem_vectorization.adapt(train_gem_texts)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02Y2WacT84P1"
      },
      "source": [
        "def format_dataset(eng, gem):\n",
        "    eng = eng_vectorization(eng)\n",
        "    gem = gem_vectorization(gem)\n",
        "    return ({\"encoder_inputs\": eng, \"decoder_inputs\": gem[:, :-1]}, gem[:, 1:])\n",
        "\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, gem_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    gem_texts = list(gem_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, gem_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()\n",
        "\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXhqmePD-aTf",
        "outputId": "afa9b173-b3c5-4d73-d45d-6218dab61d67"
      },
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (64, 20)\n",
            "inputs[\"decoder_inputs\"].shape: (64, 20)\n",
            "targets.shape: (64, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvAQ9gZxWZoO"
      },
      "source": [
        "# Transformer Model Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg9hjZz11ia0"
      },
      "source": [
        "\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super(TransformerEncoder, self).__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n",
        "        attention_output = self.attention(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
        "        )\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim\n",
        "        )\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
        "        super(TransformerDecoder, self).__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
        "        )\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "        return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
        "            axis=0,\n",
        "        )\n",
        "        return tf.tile(mask, mult)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PwI32O11ia3"
      },
      "source": [
        "embed_dim = 256\n",
        "latent_dim = 2048\n",
        "num_heads = 8\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
        "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
        "\n",
        "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "transformer = keras.Model(\n",
        "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        ")"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebjK8PmL1ia6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77c95643-8029-47c2-e1b2-386cbc833a66"
      },
      "source": [
        "epochs = 30  # This should be at least 30 for convergence\n",
        "\n",
        "transformer.summary()\n",
        "transformer.compile(\n",
        "    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "transformer.fit(train_ds, epochs=epochs, validation_data=val_ds)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " positional_embedding_14 (Posit  (None, None, 256)   3842560     ['encoder_inputs[0][0]']         \n",
            " ionalEmbedding)                                                                                  \n",
            "                                                                                                  \n",
            " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " transformer_encoder_7 (Transfo  (None, None, 256)   3155456     ['positional_embedding_14[0][0]']\n",
            " rmerEncoder)                                                                                     \n",
            "                                                                                                  \n",
            " model_14 (Functional)          (None, None, 15000)  12957080    ['decoder_inputs[0][0]',         \n",
            "                                                                  'transformer_encoder_7[0][0]']  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 19,955,096\n",
            "Trainable params: 19,955,096\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/30\n",
            "2194/2194 [==============================] - 293s 129ms/step - loss: 1.5880 - accuracy: 0.5315 - val_loss: 1.2768 - val_accuracy: 0.6019\n",
            "Epoch 2/30\n",
            "2194/2194 [==============================] - 280s 127ms/step - loss: 1.2768 - accuracy: 0.6128 - val_loss: 1.1346 - val_accuracy: 0.6408\n",
            "Epoch 3/30\n",
            "2194/2194 [==============================] - 281s 128ms/step - loss: 1.1652 - accuracy: 0.6441 - val_loss: 1.0876 - val_accuracy: 0.6598\n",
            "Epoch 4/30\n",
            "2194/2194 [==============================] - 279s 127ms/step - loss: 1.1164 - accuracy: 0.6645 - val_loss: 1.0678 - val_accuracy: 0.6696\n",
            "Epoch 5/30\n",
            "2194/2194 [==============================] - 280s 128ms/step - loss: 1.0854 - accuracy: 0.6798 - val_loss: 1.0483 - val_accuracy: 0.6791\n",
            "Epoch 6/30\n",
            "2194/2194 [==============================] - 279s 127ms/step - loss: 1.0591 - accuracy: 0.6926 - val_loss: 1.0370 - val_accuracy: 0.6860\n",
            "Epoch 7/30\n",
            "2194/2194 [==============================] - 277s 126ms/step - loss: 1.0360 - accuracy: 0.7030 - val_loss: 1.0325 - val_accuracy: 0.6895\n",
            "Epoch 8/30\n",
            "2194/2194 [==============================] - 276s 126ms/step - loss: 1.0150 - accuracy: 0.7122 - val_loss: 1.0254 - val_accuracy: 0.6936\n",
            "Epoch 9/30\n",
            "2194/2194 [==============================] - 277s 126ms/step - loss: 0.9948 - accuracy: 0.7195 - val_loss: 1.0250 - val_accuracy: 0.6961\n",
            "Epoch 10/30\n",
            "2194/2194 [==============================] - 277s 126ms/step - loss: 0.9762 - accuracy: 0.7264 - val_loss: 1.0211 - val_accuracy: 0.7001\n",
            "Epoch 11/30\n",
            "2194/2194 [==============================] - 277s 126ms/step - loss: 0.9597 - accuracy: 0.7324 - val_loss: 1.0148 - val_accuracy: 0.7020\n",
            "Epoch 12/30\n",
            "2194/2194 [==============================] - 276s 126ms/step - loss: 0.9430 - accuracy: 0.7383 - val_loss: 1.0183 - val_accuracy: 0.7024\n",
            "Epoch 13/30\n",
            "2194/2194 [==============================] - 277s 126ms/step - loss: 0.9276 - accuracy: 0.7433 - val_loss: 1.0160 - val_accuracy: 0.7030\n",
            "Epoch 14/30\n",
            "2194/2194 [==============================] - 275s 125ms/step - loss: 0.9138 - accuracy: 0.7479 - val_loss: 1.0259 - val_accuracy: 0.7022\n",
            "Epoch 15/30\n",
            "2194/2194 [==============================] - 278s 127ms/step - loss: 0.9002 - accuracy: 0.7523 - val_loss: 1.0141 - val_accuracy: 0.7071\n",
            "Epoch 16/30\n",
            "2194/2194 [==============================] - 277s 126ms/step - loss: 0.8868 - accuracy: 0.7562 - val_loss: 1.0146 - val_accuracy: 0.7060\n",
            "Epoch 17/30\n",
            "2194/2194 [==============================] - 277s 126ms/step - loss: 0.8759 - accuracy: 0.7602 - val_loss: 1.0151 - val_accuracy: 0.7076\n",
            "Epoch 18/30\n",
            "2194/2194 [==============================] - 277s 126ms/step - loss: 0.8649 - accuracy: 0.7635 - val_loss: 1.0258 - val_accuracy: 0.7057\n",
            "Epoch 19/30\n",
            "2194/2194 [==============================] - 278s 127ms/step - loss: 0.8529 - accuracy: 0.7672 - val_loss: 1.0249 - val_accuracy: 0.7066\n",
            "Epoch 20/30\n",
            "2194/2194 [==============================] - 276s 126ms/step - loss: 0.8437 - accuracy: 0.7701 - val_loss: 1.0280 - val_accuracy: 0.7070\n",
            "Epoch 21/30\n",
            "2194/2194 [==============================] - 276s 126ms/step - loss: 0.8344 - accuracy: 0.7728 - val_loss: 1.0253 - val_accuracy: 0.7099\n",
            "Epoch 22/30\n",
            "2194/2194 [==============================] - 278s 127ms/step - loss: 0.8258 - accuracy: 0.7757 - val_loss: 1.0320 - val_accuracy: 0.7100\n",
            "Epoch 23/30\n",
            "2194/2194 [==============================] - 277s 126ms/step - loss: 0.8166 - accuracy: 0.7786 - val_loss: 1.0376 - val_accuracy: 0.7080\n",
            "Epoch 24/30\n",
            "2194/2194 [==============================] - 276s 126ms/step - loss: 0.8084 - accuracy: 0.7809 - val_loss: 1.0378 - val_accuracy: 0.7075\n",
            "Epoch 25/30\n",
            "2194/2194 [==============================] - 276s 126ms/step - loss: 0.8016 - accuracy: 0.7836 - val_loss: 1.0385 - val_accuracy: 0.7087\n",
            "Epoch 26/30\n",
            "2194/2194 [==============================] - 276s 126ms/step - loss: 0.7940 - accuracy: 0.7858 - val_loss: 1.0455 - val_accuracy: 0.7079\n",
            "Epoch 27/30\n",
            "2194/2194 [==============================] - 277s 126ms/step - loss: 0.7866 - accuracy: 0.7880 - val_loss: 1.0543 - val_accuracy: 0.7060\n",
            "Epoch 28/30\n",
            "2194/2194 [==============================] - 275s 126ms/step - loss: 0.7802 - accuracy: 0.7900 - val_loss: 1.0496 - val_accuracy: 0.7083\n",
            "Epoch 29/30\n",
            "2194/2194 [==============================] - 276s 126ms/step - loss: 0.7739 - accuracy: 0.7919 - val_loss: 1.0570 - val_accuracy: 0.7062\n",
            "Epoch 30/30\n",
            "2194/2194 [==============================] - 275s 126ms/step - loss: 0.7677 - accuracy: 0.7935 - val_loss: 1.0645 - val_accuracy: 0.7065\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa48198d090>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulcNH7T6WlsF"
      },
      "source": [
        "# Decode Sequence and Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTp2pYhVFAIe"
      },
      "source": [
        "gem_vocab = gem_vectorization.get_vocabulary()\n",
        "gem_index_lookup = dict(zip(range(len(gem_vocab)), gem_vocab))\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = eng_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = gem_vectorization([decoded_sentence])[:, :-1]\n",
        "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = gem_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence\n",
        "\n",
        "\n",
        "test_eng_texts = [pair[0] for pair in test_pairs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFJmcE6wFyM3"
      },
      "source": [
        "for _ in range(30):\n",
        "    input_sentence = random.choice(test_eng_texts)\n",
        "    print(input_sentence)\n",
        "    translated = decode_sequence(input_sentence)\n",
        "    print(translated)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-m1wY8vHjc8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}